{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlJEXNelTtmv"
      },
      "source": [
        "## Category: Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ0bjAe4Tu8A"
      },
      "source": [
        "### Task 1: Import Modules and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wR7f17L3T6RC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/dolu/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /Users/dolu/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from scipy.sparse import hstack\n",
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebSFv0kYVAcq"
      },
      "source": [
        "## Category: Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Yt7mQLVKCB"
      },
      "source": [
        "### Task 2: Load and Explore the Genes and Variations Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7-dYjVi4VDLC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3321, 4)\n",
            "Index(['ID', 'Gene', 'Variation', 'Class'], dtype='object')\n",
            "   ID    Gene             Variation  Class\n",
            "0   0  FAM58A  Truncating Mutations      1\n",
            "1   1     CBL                 W802*      2\n",
            "2   2     CBL                 Q249E      2\n",
            "3   3     CBL                 N454D      3\n",
            "4   4     CBL                 L399V      4\n",
            "ID            int64\n",
            "Gene         object\n",
            "Variation    object\n",
            "Class         int64\n",
            "dtype: object\n",
            "ID           3321\n",
            "Gene          264\n",
            "Variation    2996\n",
            "Class           9\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset using the pandas library.\n",
        "df = pd.read_csv('../data/training_variants.txt')\n",
        "# Print the number of data points (rows) and features (columns).\n",
        "print(df.shape)\n",
        "# List the name of each feature.\n",
        "print(df.columns)\n",
        "# Print the first five data points.\n",
        "print(df.head())\n",
        "# Print the data type of each feature.\n",
        "print(df.dtypes)\n",
        "# Print the number of unique categories of each feature.\n",
        "print(df.nunique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U-d9o3QVQry"
      },
      "source": [
        "### Task 3: Load the Text Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sm5buZHkVpub"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred while reading the file: Expected 39677 fields in line 6, saw 41313. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.\n",
            "Attempting to read the file with a different approach...\n",
            "Dataset loaded successfully.\n",
            "Number of data points (rows): 3322\n",
            "Number of features (columns): 2\n",
            "Feature names:\n",
            "['ID', 'Text']\n",
            "    ID                                               Text\n",
            "0  NaN                                               None\n",
            "1  0.0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
            "2  1.0   Abstract Background  Non-small cell lung canc...\n",
            "3  2.0   Abstract Background  Non-small cell lung canc...\n",
            "4  3.0  Recent evidence has demonstrated that acquired...\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset into a DataFrame using the pandas library\n",
        "try:\n",
        "    df = pd.read_csv('../data/training_text.txt', sep='||', engine='python')\n",
        "except pd.errors.ParserError as e:\n",
        "    print(f\"Error occurred while reading the file: {e}\")\n",
        "    print(\"Attempting to read the file with a different approach...\")\n",
        "    \n",
        "    # If the above method fails, try reading the file manually\n",
        "    with open('../data/training_text.txt', 'r') as file:\n",
        "        lines = file.readlines()\n",
        "    \n",
        "    # Split each line into ID and Text\n",
        "    data = [line.strip().split('||', 1) for line in lines]\n",
        "    \n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=['ID', 'Text'])\n",
        "    \n",
        "    # Convert ID to integer\n",
        "    df['ID'] = pd.to_numeric(df['ID'], errors='coerce')\n",
        "\n",
        "# Check if the DataFrame was created successfully\n",
        "if df is not None and not df.empty:\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "else:\n",
        "    print(\"Failed to load the dataset.\")\n",
        "\n",
        "# Compute the number of data points (rows) and features (columns)\n",
        "num_rows, num_columns = df.shape\n",
        "print(f\"Number of data points (rows): {num_rows}\")\n",
        "print(f\"Number of features (columns): {num_columns}\")\n",
        "\n",
        "# List the name of each feature.\n",
        "print(\"Feature names:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# Print the first five data points.\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCz5xHSHVqmJ"
      },
      "source": [
        "## Category: Text Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkMUFnxdYeC-"
      },
      "source": [
        "### Task 4: Define the Function for Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NOCVw5Y9YaJA"
      },
      "outputs": [],
      "source": [
        "# Create a set of the stopwords of English using NLTK.\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define a function to perform cleaning and preprocessing on each text field. This function should:\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    \n",
        "    # Replace multiple spaces with a single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "    # Join the tokens back into a string\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    \n",
        "    return cleaned_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WzXC5WJYoyD"
      },
      "source": [
        "### Task 5: Pre-process the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQvb8CGbYr9M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1fk9ZDKYsl4"
      },
      "source": [
        "### Task 6: Merge Datasets, Clean, and Impute Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewnmTSNbYvw8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra4fhc6TZVSS"
      },
      "source": [
        "## Category: Train-test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHg0VvPvZcNg"
      },
      "source": [
        "### Task 7: Perform Train-test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv_TPnUsZatY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJTtpyhZphi"
      },
      "source": [
        "### Task 8: Check Distribution of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR-FaamGZqXr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtvl8ImIZt-C"
      },
      "source": [
        "## Category: Measure Performance Using Random Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi5cb5c-aSsE"
      },
      "source": [
        "### Task 9: Define a Function to Plot Performance Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ1CRPblaMay"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn44IC4faUda"
      },
      "source": [
        "### Task 10: Measure Metrics from a Dummy Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QiAcc9daXw6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjaegnP0aa8y"
      },
      "source": [
        "## Category: Encode the Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vakqJ5yaif0"
      },
      "source": [
        "### Task 11: Define the Functions for Response Coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrqDtGqkahdQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD5cWIZmbBok"
      },
      "source": [
        "### Task 12: Run the Function on 'Gene' and 'Variation' Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNAxtl3zbLfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkQkPDLJbMfI"
      },
      "source": [
        "### Task 13: Count Words in Text Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz41UsHhbPuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fZvJgWwbQTl"
      },
      "source": [
        "### Task 14: Define a Function for Response Coding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS1bpCoBbTi8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jxtnUiUbUQJ"
      },
      "source": [
        "### Task 15: Run the Function on Text Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywMyw8YdbXYF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2vnutLybZC0"
      },
      "source": [
        "### Task 16: One-hot Encode the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4Ufm7iRbb-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVavpF2Cbdu_"
      },
      "source": [
        "### Task 17: Normalizing the Text Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfntjIZWbhAY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1o_IjQ-bmk8"
      },
      "source": [
        "## Category: Check Feature Importances"
      ]
    },
    {
      "cell_type": "mark